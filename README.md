# Charlie-Brown-s-teacher-speaks-Hadoop.-Do-you-
You: “No, we don’t need Hadoop. We don’t have any big data.” Big Data Geek: “Wah wah wawah.”  You: “Seriously, even if we did have big data, that would be the least of our worries. We’re having enough trouble getting our ‘small’ data stored, processed and analyzed in a timely manner. First things first.”  Big Data Geek: “Wah wah wah wawah wah wah wawah.”  You: “What’s wrong with you? Do you even speak English?”  Big Data Geek: “Wawah.”  You: “Right. Anyway, the other challenge we’ve been having is that our data is growing faster than our data warehouse and our budget. Can Hadoop help with that?”  Big Data Geek: “Wah wah wawah wah wah wah wah wawah wah wawah!”  You: “Whatever, dude.”  We’ve all been there. We’re having lunch with a few colleagues, and the conversation shifts to big data. And then Charlie Brown’s teacher shows up. We try not to look at our watches. We’re having enough trouble getting our "small" data stored, processed and analyzed in a timely manner. First things first. You have just read the introductory excerpt from my white paper, A Non-Geek’s Big Data Playbook: Hadoop and the Enterprise Data Warehouse. This paper is designed to be a visual playbook for the technically savvy business professional who is still trying to understand how big data, specifically Hadoop, impacts the enterprise data game we’ve all been playing for years.  This Big Data Playbook demonstrates in six common “plays” how Apache Hadoop, the open source poster child for big data technologies, supports and extends the enterprise data warehouse (EDW) ecosystem. If you read my blog post, How Hadoop can help…even if you don’t have big data, you’re already familiar with three of these plays: staging data, processing data, and archiving data. This white paper expands on that discussion with easy-to-understand diagrams, and then delves into three more complex, more integrated plays.  If you like pictures and are
